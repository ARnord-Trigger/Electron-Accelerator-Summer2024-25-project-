{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARnord-Trigger/Electron-Accelerator-Summer2024-25-project-/blob/main/RMbipolarNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma_JWh-W-IF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "pf = \"/content/RMBipolar02082023_081612.csv\"\n",
        "df = pd.read_csv(pf)"
      ],
      "metadata": {
        "id": "4RhnRTgE0Off"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OlcJk4_80VXl",
        "outputId": "24c83853-8906-4b8b-d7b2-03ff976ccad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0         1         2         3         4         5         6         7  \\\n",
              "0    51 -0.093500 -0.209250 -0.252500 -0.112500  0.111875  0.129875  0.139375   \n",
              "1    52 -0.111125 -0.224500 -0.277250 -0.126250  0.114750  0.151375  0.166875   \n",
              "2    53 -0.125875 -0.262875 -0.211500 -0.099125  0.007625  0.145875  0.211750   \n",
              "3    54 -0.113375 -0.245625 -0.204500 -0.084500 -0.005875  0.128000  0.193750   \n",
              "4    55  0.073375  0.121625  0.068750 -0.003000 -0.076750 -0.084875 -0.103875   \n",
              "..  ...       ...       ...       ...       ...       ...       ...       ...   \n",
              "83  134 -0.002125 -0.003875 -0.008375 -0.000875  0.004250  0.000875 -0.001875   \n",
              "84  135 -0.002625 -0.011500 -0.007125 -0.000250  0.007875 -0.000750 -0.001750   \n",
              "85  136  0.001875  0.000250  0.002625  0.001875 -0.001000 -0.003250 -0.003750   \n",
              "86  137 -0.002125 -0.007625 -0.009500 -0.001250  0.005000  0.002125 -0.000750   \n",
              "87  138 -0.001500 -0.000375  0.000500 -0.000625 -0.001625 -0.000500  0.001125   \n",
              "\n",
              "           8         9  ...       103       104       105       106       107  \\\n",
              "0  -0.105250 -0.252125  ...  0.007500 -0.010000 -0.003250  0.002875  0.003250   \n",
              "1  -0.114750 -0.290500  ... -0.004500 -0.009500 -0.001625  0.003375  0.003625   \n",
              "2  -0.085250 -0.274000  ...  0.006000  0.002625 -0.000500  0.003125  0.001250   \n",
              "3  -0.069625 -0.239625  ... -0.003500 -0.006500  0.003125  0.008000  0.005750   \n",
              "4   0.068375  0.180500  ... -0.002500  0.011750  0.003250 -0.003375 -0.002250   \n",
              "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
              "83 -0.003375  0.000375  ...  0.016125  0.158125  0.113000  0.177000  0.131250   \n",
              "84 -0.002375  0.001375  ... -0.015750  0.101625  0.096875  0.186125  0.113250   \n",
              "85  0.003625  0.005375  ... -0.108500 -0.160250 -0.026125  0.083500  0.110625   \n",
              "86 -0.000750 -0.003125  ... -0.125000 -0.218625 -0.065375  0.043250  0.107500   \n",
              "87  0.002750 -0.004125  ...  0.041875 -0.198625 -0.178750 -0.334625 -0.150125   \n",
              "\n",
              "         108       109       110       111       112  \n",
              "0   0.018125  0.012625  0.001250  0.004125 -0.001500  \n",
              "1   0.024250  0.014750  0.004250  0.001500 -0.003875  \n",
              "2   0.019875  0.005125  0.000875  0.004750  0.001000  \n",
              "3   0.013750  0.002750  0.002500 -0.003250 -0.000125  \n",
              "4  -0.010750 -0.007625  0.000000 -0.000500  0.001500  \n",
              "..       ...       ...       ...       ...       ...  \n",
              "83  0.099125  0.042375 -0.028750 -0.218750 -0.103375  \n",
              "84  0.127375  0.090875 -0.002000 -0.178875 -0.105250  \n",
              "85  0.136125  0.193875  0.062750  0.090250 -0.023750  \n",
              "86  0.189000  0.208875  0.079625  0.168750  0.003750  \n",
              "87  0.112500  0.288000  0.112125  0.347125  0.190875  \n",
              "\n",
              "[88 rows x 113 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-814742c8-fd7a-48a4-9a8a-59531bfe534e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51</td>\n",
              "      <td>-0.093500</td>\n",
              "      <td>-0.209250</td>\n",
              "      <td>-0.252500</td>\n",
              "      <td>-0.112500</td>\n",
              "      <td>0.111875</td>\n",
              "      <td>0.129875</td>\n",
              "      <td>0.139375</td>\n",
              "      <td>-0.105250</td>\n",
              "      <td>-0.252125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>-0.003250</td>\n",
              "      <td>0.002875</td>\n",
              "      <td>0.003250</td>\n",
              "      <td>0.018125</td>\n",
              "      <td>0.012625</td>\n",
              "      <td>0.001250</td>\n",
              "      <td>0.004125</td>\n",
              "      <td>-0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52</td>\n",
              "      <td>-0.111125</td>\n",
              "      <td>-0.224500</td>\n",
              "      <td>-0.277250</td>\n",
              "      <td>-0.126250</td>\n",
              "      <td>0.114750</td>\n",
              "      <td>0.151375</td>\n",
              "      <td>0.166875</td>\n",
              "      <td>-0.114750</td>\n",
              "      <td>-0.290500</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004500</td>\n",
              "      <td>-0.009500</td>\n",
              "      <td>-0.001625</td>\n",
              "      <td>0.003375</td>\n",
              "      <td>0.003625</td>\n",
              "      <td>0.024250</td>\n",
              "      <td>0.014750</td>\n",
              "      <td>0.004250</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>-0.003875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>53</td>\n",
              "      <td>-0.125875</td>\n",
              "      <td>-0.262875</td>\n",
              "      <td>-0.211500</td>\n",
              "      <td>-0.099125</td>\n",
              "      <td>0.007625</td>\n",
              "      <td>0.145875</td>\n",
              "      <td>0.211750</td>\n",
              "      <td>-0.085250</td>\n",
              "      <td>-0.274000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>-0.000500</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>0.001250</td>\n",
              "      <td>0.019875</td>\n",
              "      <td>0.005125</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54</td>\n",
              "      <td>-0.113375</td>\n",
              "      <td>-0.245625</td>\n",
              "      <td>-0.204500</td>\n",
              "      <td>-0.084500</td>\n",
              "      <td>-0.005875</td>\n",
              "      <td>0.128000</td>\n",
              "      <td>0.193750</td>\n",
              "      <td>-0.069625</td>\n",
              "      <td>-0.239625</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003500</td>\n",
              "      <td>-0.006500</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.005750</td>\n",
              "      <td>0.013750</td>\n",
              "      <td>0.002750</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>-0.003250</td>\n",
              "      <td>-0.000125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55</td>\n",
              "      <td>0.073375</td>\n",
              "      <td>0.121625</td>\n",
              "      <td>0.068750</td>\n",
              "      <td>-0.003000</td>\n",
              "      <td>-0.076750</td>\n",
              "      <td>-0.084875</td>\n",
              "      <td>-0.103875</td>\n",
              "      <td>0.068375</td>\n",
              "      <td>0.180500</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002500</td>\n",
              "      <td>0.011750</td>\n",
              "      <td>0.003250</td>\n",
              "      <td>-0.003375</td>\n",
              "      <td>-0.002250</td>\n",
              "      <td>-0.010750</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000500</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>134</td>\n",
              "      <td>-0.002125</td>\n",
              "      <td>-0.003875</td>\n",
              "      <td>-0.008375</td>\n",
              "      <td>-0.000875</td>\n",
              "      <td>0.004250</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>-0.001875</td>\n",
              "      <td>-0.003375</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016125</td>\n",
              "      <td>0.158125</td>\n",
              "      <td>0.113000</td>\n",
              "      <td>0.177000</td>\n",
              "      <td>0.131250</td>\n",
              "      <td>0.099125</td>\n",
              "      <td>0.042375</td>\n",
              "      <td>-0.028750</td>\n",
              "      <td>-0.218750</td>\n",
              "      <td>-0.103375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>135</td>\n",
              "      <td>-0.002625</td>\n",
              "      <td>-0.011500</td>\n",
              "      <td>-0.007125</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.007875</td>\n",
              "      <td>-0.000750</td>\n",
              "      <td>-0.001750</td>\n",
              "      <td>-0.002375</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015750</td>\n",
              "      <td>0.101625</td>\n",
              "      <td>0.096875</td>\n",
              "      <td>0.186125</td>\n",
              "      <td>0.113250</td>\n",
              "      <td>0.127375</td>\n",
              "      <td>0.090875</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>-0.178875</td>\n",
              "      <td>-0.105250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>136</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.002625</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>-0.003250</td>\n",
              "      <td>-0.003750</td>\n",
              "      <td>0.003625</td>\n",
              "      <td>0.005375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108500</td>\n",
              "      <td>-0.160250</td>\n",
              "      <td>-0.026125</td>\n",
              "      <td>0.083500</td>\n",
              "      <td>0.110625</td>\n",
              "      <td>0.136125</td>\n",
              "      <td>0.193875</td>\n",
              "      <td>0.062750</td>\n",
              "      <td>0.090250</td>\n",
              "      <td>-0.023750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>137</td>\n",
              "      <td>-0.002125</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>-0.009500</td>\n",
              "      <td>-0.001250</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.002125</td>\n",
              "      <td>-0.000750</td>\n",
              "      <td>-0.000750</td>\n",
              "      <td>-0.003125</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>-0.218625</td>\n",
              "      <td>-0.065375</td>\n",
              "      <td>0.043250</td>\n",
              "      <td>0.107500</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.208875</td>\n",
              "      <td>0.079625</td>\n",
              "      <td>0.168750</td>\n",
              "      <td>0.003750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>138</td>\n",
              "      <td>-0.001500</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>-0.000625</td>\n",
              "      <td>-0.001625</td>\n",
              "      <td>-0.000500</td>\n",
              "      <td>0.001125</td>\n",
              "      <td>0.002750</td>\n",
              "      <td>-0.004125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041875</td>\n",
              "      <td>-0.198625</td>\n",
              "      <td>-0.178750</td>\n",
              "      <td>-0.334625</td>\n",
              "      <td>-0.150125</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.112125</td>\n",
              "      <td>0.347125</td>\n",
              "      <td>0.190875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88 rows Ã— 113 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-814742c8-fd7a-48a4-9a8a-59531bfe534e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-814742c8-fd7a-48a4-9a8a-59531bfe534e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-814742c8-fd7a-48a4-9a8a-59531bfe534e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd0f9300-cfb9-4cad-b961-2b0f3c641fa2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd0f9300-cfb9-4cad-b961-2b0f3c641fa2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd0f9300-cfb9-4cad-b961-2b0f3c641fa2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e66a2319-2366-4343-a896-ab16ee6171d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e66a2319-2366-4343-a896-ab16ee6171d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RM = df.values\n",
        "RM=RM[:,1:]"
      ],
      "metadata": {
        "id": "fl2jBSmq0WPF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I_1 = np.identity(48)\n",
        "I_2 = np.identity(40)\n",
        "BPI_x1 = RM[0:49,0:57].T\n",
        "BPI_x2 = RM[49:89,0:57].T\n",
        "BPI_y1 = RM[0:49,57:113].T\n",
        "BPI_y2 = RM[49:89,57:113].T"
      ],
      "metadata": {
        "id": "qOunFnQh0hQd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_dims):\n",
        "        self.layer_dims = layer_dims\n",
        "        self.parameters = self.initialize_parameters(layer_dims)\n",
        "        self.cache = {}\n",
        "        self.grads = {}\n",
        "        self.epsilon = 1e-8  # Small number to avoid division by zero in batch normalization\n",
        "        self.beta = 0.9  # Parameter for the Adam optimizer\n",
        "        self.beta1 = 0.9  # Parameter for Adam optimizer\n",
        "        self.beta2 = 0.999  # Parameter for Adam optimizer\n",
        "        self.learning_rate = 0.001  # Learning rate for Adam optimizer\n",
        "\n",
        "    def initialize_parameters(self, layer_dims):\n",
        "        parameters = {}\n",
        "        L = len(layer_dims)\n",
        "\n",
        "        for l in range(1, L):\n",
        "            parameters[f\"W{l}\"] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2 / layer_dims[l-1])  # He initialization\n",
        "            parameters[f\"b{l}\"] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "        return parameters\n",
        "\n",
        "    def relu(self, Z):\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def softmax(self, Z):\n",
        "        exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "        return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
        "\n",
        "    def forward_propagation(self, X):\n",
        "        A = X\n",
        "        L = len(self.layer_dims) - 1\n",
        "        self.cache[\"A0\"] = X\n",
        "        for l in range(1, L):\n",
        "            W = self.parameters[f\"W{l}\"]\n",
        "            b = self.parameters[f\"b{l}\"]\n",
        "            Z = np.dot(W, A) + b\n",
        "            A = self.relu(Z)\n",
        "            self.cache[f\"Z{l}\"] = Z\n",
        "            self.cache[f\"A{l}\"] = A\n",
        "\n",
        "            # Batch normalization\n",
        "            mean = np.mean(A, axis=1, keepdims=True)\n",
        "            var = np.var(A, axis=1, keepdims=True)\n",
        "            A_normalized = (A - mean) / np.sqrt(var + self.epsilon)\n",
        "            self.cache[f\"A{l}_normalized\"] = A_normalized\n",
        "\n",
        "        # Output layer\n",
        "        WL = self.parameters[f\"W{L}\"]\n",
        "        bL = self.parameters[f\"b{L}\"]\n",
        "        ZL = np.dot(WL, A) + bL\n",
        "        AL = self.softmax(ZL)\n",
        "        self.cache[f\"Z{L}\"] = ZL\n",
        "        self.cache[f\"A{L}\"] = AL\n",
        "        # print(AL.shape)\n",
        "\n",
        "        return AL\n",
        "\n",
        "    def compute_loss(self, AL, Y):\n",
        "        m = Y.shape[1]\n",
        "        cost = np.sum((AL-Y)**2) / m  # Cross-entropy loss\n",
        "        return cost\n",
        "\n",
        "    def backward_propagation(self, X, Y):\n",
        "        m = Y.shape[1]\n",
        "        L = len(self.layer_dims) - 1\n",
        "        AL = self.cache[f\"A{L}\"]\n",
        "        dAL = AL - Y\n",
        "\n",
        "        # Output layer gradients\n",
        "        dZL = dAL\n",
        "        self.grads[f\"dW{L}\"] = np.dot(dZL, self.cache[f\"A{L-1}\"].T) / m\n",
        "        self.grads[f\"db{L}\"] = np.sum(dZL, axis=1, keepdims=True) / m\n",
        "\n",
        "        dA_prev = np.dot(self.parameters[f\"W{L}\"].T, dZL)\n",
        "\n",
        "        # Hidden layers gradients\n",
        "        for l in reversed(range(1, L)):\n",
        "            dZ = dA_prev * (self.cache[f\"Z{l}\"] > 0).astype(int)  # ReLU derivative\n",
        "            self.grads[f\"dW{l}\"] = np.dot(dZ, self.cache[f\"A{l-1}\"].T) / m\n",
        "            self.grads[f\"db{l}\"] = np.sum(dZ, axis=1, keepdims=True) / m\n",
        "\n",
        "            # Batch normalization gradients\n",
        "            dA_prev = np.dot(self.parameters[f\"W{l}\"].T, dZ)\n",
        "\n",
        "    def update_parameters(self):\n",
        "        L = len(self.layer_dims) - 1\n",
        "\n",
        "        for l in range(1, L + 1):\n",
        "            self.parameters[f\"W{l}\"] -= self.learning_rate * self.grads[f\"dW{l}\"]\n",
        "            self.parameters[f\"b{l}\"] -= self.learning_rate * self.grads[f\"db{l}\"]\n",
        "\n",
        "    def train(self, X, Y, epochs=100, batch_size=12):\n",
        "        m = X.shape[1]\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(0, m, batch_size):\n",
        "                X_batch = X[:, i:i+batch_size]\n",
        "                Y_batch = Y[:, i:i+batch_size]\n",
        "\n",
        "                # Forward propagation\n",
        "                AL = self.forward_propagation(X_batch)\n",
        "\n",
        "                # Compute cost\n",
        "                # print(f\"AL:{AL.shape}\")\n",
        "                # print(f\"Y_batch:{Y_batch.shape}\")\n",
        "                cost = self.compute_loss(AL, Y_batch)\n",
        "\n",
        "                # Backward propagation\n",
        "                self.backward_propagation(X_batch, Y_batch)\n",
        "\n",
        "                # Update parameters\n",
        "                self.update_parameters()\n",
        "\n",
        "                if i % 1000 == 0:\n",
        "                    print(f\"Epoch {epoch+1}/{epochs}, Batch {i//batch_size+1}/{m//batch_size}, Cost: {cost:.4f}\")\n"
      ],
      "metadata": {
        "id": "3V7LG7CNMfOg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I_1 = np.identity(48)\n",
        "I_2 = np.identity(40)\n",
        "BPI_x1 = RM[0:49,0:57].T\n",
        "BPI_x2 = RM[49:89,0:57].T\n",
        "BPI_y1 = RM[0:49,57:113].T\n",
        "BPI_y2 = RM[49:89,57:113].T"
      ],
      "metadata": {
        "id": "z8q2eFbvHYWA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = I_1 = np.identity(48)\n",
        "Y_train = BPI_x1 = RM[0:48,0:56].T\n",
        "layers_dims = [48,108,108,96,96,64,56]\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "id": "1Ts2R-C2Hnof",
        "outputId": "acce12fe-05a5-4d10-d9b9-3d37d9cb25d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48, 48)\n",
            "(56, 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# y_train = y_train.reshape(-1, 1)\n",
        "# y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Normalize the input data (optional)\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "# X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
        "\n",
        "# Define the architecture of the neural network\n",
        "layer_dims = [X_train.shape[0], 108, 108, 96,56]  # Input dimension, hidden layer dimensions, output dimension\n",
        "epochs = 190\n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "# Initialize and train the neural network\n",
        "model = NeuralNetwork(layer_dims)\n",
        "model.train(X_train, Y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "def accuracy(predictions, labels):\n",
        "    return np.mean(np.argmax(predictions, axis=0) == np.argmax(labels, axis=0))\n",
        "\n",
        "# Forward pass on the test set\n",
        "# predictions = model.forward_propagation(X_test)\n",
        "# acc = accuracy(predictions, y_test_encoded)\n",
        "\n",
        "# print(f\"Test Accuracy: {acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "3UYUHzd0FQST",
        "outputId": "dd55c728-c9c1-4cc1-d98f-abed516872fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/190, Batch 1/4, Cost: 1.1840\n",
            "Epoch 2/190, Batch 1/4, Cost: 1.1812\n",
            "Epoch 3/190, Batch 1/4, Cost: 1.1786\n",
            "Epoch 4/190, Batch 1/4, Cost: 1.1761\n",
            "Epoch 5/190, Batch 1/4, Cost: 1.1737\n",
            "Epoch 6/190, Batch 1/4, Cost: 1.1714\n",
            "Epoch 7/190, Batch 1/4, Cost: 1.1691\n",
            "Epoch 8/190, Batch 1/4, Cost: 1.1669\n",
            "Epoch 9/190, Batch 1/4, Cost: 1.1647\n",
            "Epoch 10/190, Batch 1/4, Cost: 1.1626\n",
            "Epoch 11/190, Batch 1/4, Cost: 1.1606\n",
            "Epoch 12/190, Batch 1/4, Cost: 1.1587\n",
            "Epoch 13/190, Batch 1/4, Cost: 1.1568\n",
            "Epoch 14/190, Batch 1/4, Cost: 1.1550\n",
            "Epoch 15/190, Batch 1/4, Cost: 1.1533\n",
            "Epoch 16/190, Batch 1/4, Cost: 1.1515\n",
            "Epoch 17/190, Batch 1/4, Cost: 1.1497\n",
            "Epoch 18/190, Batch 1/4, Cost: 1.1479\n",
            "Epoch 19/190, Batch 1/4, Cost: 1.1462\n",
            "Epoch 20/190, Batch 1/4, Cost: 1.1445\n",
            "Epoch 21/190, Batch 1/4, Cost: 1.1428\n",
            "Epoch 22/190, Batch 1/4, Cost: 1.1413\n",
            "Epoch 23/190, Batch 1/4, Cost: 1.1397\n",
            "Epoch 24/190, Batch 1/4, Cost: 1.1382\n",
            "Epoch 25/190, Batch 1/4, Cost: 1.1367\n",
            "Epoch 26/190, Batch 1/4, Cost: 1.1353\n",
            "Epoch 27/190, Batch 1/4, Cost: 1.1339\n",
            "Epoch 28/190, Batch 1/4, Cost: 1.1325\n",
            "Epoch 29/190, Batch 1/4, Cost: 1.1312\n",
            "Epoch 30/190, Batch 1/4, Cost: 1.1299\n",
            "Epoch 31/190, Batch 1/4, Cost: 1.1286\n",
            "Epoch 32/190, Batch 1/4, Cost: 1.1274\n",
            "Epoch 33/190, Batch 1/4, Cost: 1.1262\n",
            "Epoch 34/190, Batch 1/4, Cost: 1.1250\n",
            "Epoch 35/190, Batch 1/4, Cost: 1.1238\n",
            "Epoch 36/190, Batch 1/4, Cost: 1.1226\n",
            "Epoch 37/190, Batch 1/4, Cost: 1.1215\n",
            "Epoch 38/190, Batch 1/4, Cost: 1.1203\n",
            "Epoch 39/190, Batch 1/4, Cost: 1.1192\n",
            "Epoch 40/190, Batch 1/4, Cost: 1.1180\n",
            "Epoch 41/190, Batch 1/4, Cost: 1.1169\n",
            "Epoch 42/190, Batch 1/4, Cost: 1.1158\n",
            "Epoch 43/190, Batch 1/4, Cost: 1.1148\n",
            "Epoch 44/190, Batch 1/4, Cost: 1.1137\n",
            "Epoch 45/190, Batch 1/4, Cost: 1.1126\n",
            "Epoch 46/190, Batch 1/4, Cost: 1.1116\n",
            "Epoch 47/190, Batch 1/4, Cost: 1.1105\n",
            "Epoch 48/190, Batch 1/4, Cost: 1.1095\n",
            "Epoch 49/190, Batch 1/4, Cost: 1.1085\n",
            "Epoch 50/190, Batch 1/4, Cost: 1.1075\n",
            "Epoch 51/190, Batch 1/4, Cost: 1.1066\n",
            "Epoch 52/190, Batch 1/4, Cost: 1.1056\n",
            "Epoch 53/190, Batch 1/4, Cost: 1.1047\n",
            "Epoch 54/190, Batch 1/4, Cost: 1.1038\n",
            "Epoch 55/190, Batch 1/4, Cost: 1.1029\n",
            "Epoch 56/190, Batch 1/4, Cost: 1.1020\n",
            "Epoch 57/190, Batch 1/4, Cost: 1.1011\n",
            "Epoch 58/190, Batch 1/4, Cost: 1.1002\n",
            "Epoch 59/190, Batch 1/4, Cost: 1.0993\n",
            "Epoch 60/190, Batch 1/4, Cost: 1.0985\n",
            "Epoch 61/190, Batch 1/4, Cost: 1.0977\n",
            "Epoch 62/190, Batch 1/4, Cost: 1.0968\n",
            "Epoch 63/190, Batch 1/4, Cost: 1.0960\n",
            "Epoch 64/190, Batch 1/4, Cost: 1.0952\n",
            "Epoch 65/190, Batch 1/4, Cost: 1.0945\n",
            "Epoch 66/190, Batch 1/4, Cost: 1.0937\n",
            "Epoch 67/190, Batch 1/4, Cost: 1.0930\n",
            "Epoch 68/190, Batch 1/4, Cost: 1.0922\n",
            "Epoch 69/190, Batch 1/4, Cost: 1.0915\n",
            "Epoch 70/190, Batch 1/4, Cost: 1.0907\n",
            "Epoch 71/190, Batch 1/4, Cost: 1.0900\n",
            "Epoch 72/190, Batch 1/4, Cost: 1.0892\n",
            "Epoch 73/190, Batch 1/4, Cost: 1.0885\n",
            "Epoch 74/190, Batch 1/4, Cost: 1.0877\n",
            "Epoch 75/190, Batch 1/4, Cost: 1.0871\n",
            "Epoch 76/190, Batch 1/4, Cost: 1.0863\n",
            "Epoch 77/190, Batch 1/4, Cost: 1.0857\n",
            "Epoch 78/190, Batch 1/4, Cost: 1.0850\n",
            "Epoch 79/190, Batch 1/4, Cost: 1.0843\n",
            "Epoch 80/190, Batch 1/4, Cost: 1.0837\n",
            "Epoch 81/190, Batch 1/4, Cost: 1.0830\n",
            "Epoch 82/190, Batch 1/4, Cost: 1.0824\n",
            "Epoch 83/190, Batch 1/4, Cost: 1.0818\n",
            "Epoch 84/190, Batch 1/4, Cost: 1.0811\n",
            "Epoch 85/190, Batch 1/4, Cost: 1.0805\n",
            "Epoch 86/190, Batch 1/4, Cost: 1.0799\n",
            "Epoch 87/190, Batch 1/4, Cost: 1.0793\n",
            "Epoch 88/190, Batch 1/4, Cost: 1.0786\n",
            "Epoch 89/190, Batch 1/4, Cost: 1.0781\n",
            "Epoch 90/190, Batch 1/4, Cost: 1.0774\n",
            "Epoch 91/190, Batch 1/4, Cost: 1.0768\n",
            "Epoch 92/190, Batch 1/4, Cost: 1.0763\n",
            "Epoch 93/190, Batch 1/4, Cost: 1.0756\n",
            "Epoch 94/190, Batch 1/4, Cost: 1.0749\n",
            "Epoch 95/190, Batch 1/4, Cost: 1.0743\n",
            "Epoch 96/190, Batch 1/4, Cost: 1.0736\n",
            "Epoch 97/190, Batch 1/4, Cost: 1.0730\n",
            "Epoch 98/190, Batch 1/4, Cost: 1.0723\n",
            "Epoch 99/190, Batch 1/4, Cost: 1.0717\n",
            "Epoch 100/190, Batch 1/4, Cost: 1.0711\n",
            "Epoch 101/190, Batch 1/4, Cost: 1.0704\n",
            "Epoch 102/190, Batch 1/4, Cost: 1.0698\n",
            "Epoch 103/190, Batch 1/4, Cost: 1.0692\n",
            "Epoch 104/190, Batch 1/4, Cost: 1.0686\n",
            "Epoch 105/190, Batch 1/4, Cost: 1.0679\n",
            "Epoch 106/190, Batch 1/4, Cost: 1.0673\n",
            "Epoch 107/190, Batch 1/4, Cost: 1.0667\n",
            "Epoch 108/190, Batch 1/4, Cost: 1.0661\n",
            "Epoch 109/190, Batch 1/4, Cost: 1.0655\n",
            "Epoch 110/190, Batch 1/4, Cost: 1.0648\n",
            "Epoch 111/190, Batch 1/4, Cost: 1.0642\n",
            "Epoch 112/190, Batch 1/4, Cost: 1.0637\n",
            "Epoch 113/190, Batch 1/4, Cost: 1.0630\n",
            "Epoch 114/190, Batch 1/4, Cost: 1.0625\n",
            "Epoch 115/190, Batch 1/4, Cost: 1.0619\n",
            "Epoch 116/190, Batch 1/4, Cost: 1.0613\n",
            "Epoch 117/190, Batch 1/4, Cost: 1.0607\n",
            "Epoch 118/190, Batch 1/4, Cost: 1.0602\n",
            "Epoch 119/190, Batch 1/4, Cost: 1.0596\n",
            "Epoch 120/190, Batch 1/4, Cost: 1.0590\n",
            "Epoch 121/190, Batch 1/4, Cost: 1.0584\n",
            "Epoch 122/190, Batch 1/4, Cost: 1.0578\n",
            "Epoch 123/190, Batch 1/4, Cost: 1.0573\n",
            "Epoch 124/190, Batch 1/4, Cost: 1.0566\n",
            "Epoch 125/190, Batch 1/4, Cost: 1.0560\n",
            "Epoch 126/190, Batch 1/4, Cost: 1.0554\n",
            "Epoch 127/190, Batch 1/4, Cost: 1.0548\n",
            "Epoch 128/190, Batch 1/4, Cost: 1.0542\n",
            "Epoch 129/190, Batch 1/4, Cost: 1.0536\n",
            "Epoch 130/190, Batch 1/4, Cost: 1.0529\n",
            "Epoch 131/190, Batch 1/4, Cost: 1.0523\n",
            "Epoch 132/190, Batch 1/4, Cost: 1.0517\n",
            "Epoch 133/190, Batch 1/4, Cost: 1.0511\n",
            "Epoch 134/190, Batch 1/4, Cost: 1.0505\n",
            "Epoch 135/190, Batch 1/4, Cost: 1.0498\n",
            "Epoch 136/190, Batch 1/4, Cost: 1.0492\n",
            "Epoch 137/190, Batch 1/4, Cost: 1.0486\n",
            "Epoch 138/190, Batch 1/4, Cost: 1.0480\n",
            "Epoch 139/190, Batch 1/4, Cost: 1.0474\n",
            "Epoch 140/190, Batch 1/4, Cost: 1.0467\n",
            "Epoch 141/190, Batch 1/4, Cost: 1.0460\n",
            "Epoch 142/190, Batch 1/4, Cost: 1.0453\n",
            "Epoch 143/190, Batch 1/4, Cost: 1.0446\n",
            "Epoch 144/190, Batch 1/4, Cost: 1.0440\n",
            "Epoch 145/190, Batch 1/4, Cost: 1.0433\n",
            "Epoch 146/190, Batch 1/4, Cost: 1.0426\n",
            "Epoch 147/190, Batch 1/4, Cost: 1.0420\n",
            "Epoch 148/190, Batch 1/4, Cost: 1.0413\n",
            "Epoch 149/190, Batch 1/4, Cost: 1.0407\n",
            "Epoch 150/190, Batch 1/4, Cost: 1.0401\n",
            "Epoch 151/190, Batch 1/4, Cost: 1.0394\n",
            "Epoch 152/190, Batch 1/4, Cost: 1.0388\n",
            "Epoch 153/190, Batch 1/4, Cost: 1.0382\n",
            "Epoch 154/190, Batch 1/4, Cost: 1.0376\n",
            "Epoch 155/190, Batch 1/4, Cost: 1.0369\n",
            "Epoch 156/190, Batch 1/4, Cost: 1.0363\n",
            "Epoch 157/190, Batch 1/4, Cost: 1.0357\n",
            "Epoch 158/190, Batch 1/4, Cost: 1.0351\n",
            "Epoch 159/190, Batch 1/4, Cost: 1.0345\n",
            "Epoch 160/190, Batch 1/4, Cost: 1.0338\n",
            "Epoch 161/190, Batch 1/4, Cost: 1.0332\n",
            "Epoch 162/190, Batch 1/4, Cost: 1.0325\n",
            "Epoch 163/190, Batch 1/4, Cost: 1.0319\n",
            "Epoch 164/190, Batch 1/4, Cost: 1.0312\n",
            "Epoch 165/190, Batch 1/4, Cost: 1.0305\n",
            "Epoch 166/190, Batch 1/4, Cost: 1.0299\n",
            "Epoch 167/190, Batch 1/4, Cost: 1.0293\n",
            "Epoch 168/190, Batch 1/4, Cost: 1.0287\n",
            "Epoch 169/190, Batch 1/4, Cost: 1.0281\n",
            "Epoch 170/190, Batch 1/4, Cost: 1.0274\n",
            "Epoch 171/190, Batch 1/4, Cost: 1.0268\n",
            "Epoch 172/190, Batch 1/4, Cost: 1.0263\n",
            "Epoch 173/190, Batch 1/4, Cost: 1.0257\n",
            "Epoch 174/190, Batch 1/4, Cost: 1.0251\n",
            "Epoch 175/190, Batch 1/4, Cost: 1.0246\n",
            "Epoch 176/190, Batch 1/4, Cost: 1.0241\n",
            "Epoch 177/190, Batch 1/4, Cost: 1.0237\n",
            "Epoch 178/190, Batch 1/4, Cost: 1.0232\n",
            "Epoch 179/190, Batch 1/4, Cost: 1.0228\n",
            "Epoch 180/190, Batch 1/4, Cost: 1.0224\n",
            "Epoch 181/190, Batch 1/4, Cost: 1.0220\n",
            "Epoch 182/190, Batch 1/4, Cost: 1.0216\n",
            "Epoch 183/190, Batch 1/4, Cost: 1.0212\n",
            "Epoch 184/190, Batch 1/4, Cost: 1.0209\n",
            "Epoch 185/190, Batch 1/4, Cost: 1.0205\n",
            "Epoch 186/190, Batch 1/4, Cost: 1.0202\n",
            "Epoch 187/190, Batch 1/4, Cost: 1.0199\n",
            "Epoch 188/190, Batch 1/4, Cost: 1.0197\n",
            "Epoch 189/190, Batch 1/4, Cost: 1.0195\n",
            "Epoch 190/190, Batch 1/4, Cost: 1.0193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jipsZeT5IerO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22dMzpxfJAQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}